{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to Text Lab","text":"<p>Text Lab is an interactive platform designed to make advanced Natural Language Processing (NLP) tools accessible to researchers and students at the University of Bern.</p> <p>Developed by the Data Science Lab (DSL), Text Lab allows you to process documents, audio, and data without needing to write code.</p>"},{"location":"#data-privacy-security","title":"\ud83d\udd12 Data Privacy &amp; Security","text":"<p>Why use Text Lab?</p> <p>One of the primary advantages of Text Lab is data sovereignty</p> <ul> <li>Internal Processing: All processing happens entirely within the University of Bern's network infrastructure (UBELIX).</li> <li>No Third Parties: Unlike commercial cloud services (like ChatGPT or Google Cloud), your data is never sent to external servers.</li> <li>Sensitive Data: Text Lab is the better choice for working with potentially sensitive research data (e.g., for interviews and/or non-public documents).</li> </ul>"},{"location":"#available-tools","title":"Available Tools","text":"<ul> <li>Transcription: Convert audio files to text with high accuracy, featuring a specialized model for Swiss German.</li> <li>OCR (Optical Character Recognition): Extract text from scanned PDFs using state-of-the-art AI models.</li> <li>Chat: Interact with local Large Language Models (LLMs) securely.</li> <li>Data Visualization: Generate insights and plots from your data.</li> </ul> <p>For processing large amount of data, please contact DSL.</p>"},{"location":"#getting-support","title":"Getting Support","text":"<p>If you encounter issues, need any data science, research IT support, or have questions about using Text Lab, please contact the Data Science Lab: \ud83d\udce7 support.dsl@unibe.ch</p>"},{"location":"knowledge_graph/","title":"Knowledge Graph","text":"<p>The Knowledge Graph feature uses large language models (LLMs) to automatically extract key topics from the abstracts of your uploaded scientific papers. It then builds an interactive graph that reveals hidden connections across your literature collection \u2014 making it easy to explore themes, spot patterns, and navigate complex research landscapes.</p>"},{"location":"knowledge_graph/#step-1-build-your-corpus","title":"Step 1 \u2014 Build Your Corpus","text":"<p>Start by pointing the app to a folder containing your PDF collection. The app will scan the folder and list all detected PDFs so you can confirm you're working with the right files. Once ready, click \"Generate Corpus\" to kick off the extraction process.</p> <p>Under the hood, this step uses GROBID to parse each PDF and convert it into a structured XML format optimised for downstream processing. The output is saved to a new folder named <code>your_collection_project_corpus</code>.</p> <p>Smart caching: This step is computationally intensive, but the app checks for an existing corpus before reprocessing. It will only reprocess papers that are new or have changed \u2014 and reports exactly how many files were updated.</p> <p>Once your corpus is built and nothing has changed, you can skip straight to Step 2 on future runs.</p> <p>A CSV export is also generated at this stage, giving you a human-readable summary of the extraction results. Use it to spot any issues with how GROBID processed individual papers.</p> <p>Lost your CSV? No problem \u2014 use Step 1b: \"Rebuild Corpus Table\" to regenerate it at any time. Just point to the folder containing your corpora; they'll be detected automatically so you can select the one you need.</p>"},{"location":"knowledge_graph/#step-2-extract-topics","title":"Step 2 \u2014 Extract Topics","text":"<p>With your corpus ready, the app uses an LLM to read each paper's abstract and extract 5\u20138 concise topic phrases. Each topic is then assigned a category, which serves as a shared node when connecting papers in the graph.</p> <p>Point to the folder containing your project corpora \u2014 they'll appear automatically in the dropdown. Select the corpus you want to process and let the LLM do the work.</p> <p>The resulting topics are saved to a JSON file that feeds directly into Step 3. You can also download this file at any time for offline inspection or further analysis.</p>"},{"location":"knowledge_graph/#step-3-visualise-your-data","title":"Step 3 \u2014 Visualise Your Data","text":"<p>If you've already completed topic extraction, you can jump straight here. Point to your corpora folder, choose a corpus from the dropdown, and start exploring your data through two complementary views:</p>"},{"location":"knowledge_graph/#ego-graphs","title":"Ego Graphs","text":"<p>Ego graphs let you examine each paper individually. They show the topics, authors, and other metadata associated with a single paper as a local graph. Use the checkboxes to toggle which node types are displayed, then click \"Generate Ego Graph\" to refresh the view.</p> <p>You can download any visualisation as an HTML file for offline use or sharing.</p>"},{"location":"knowledge_graph/#full-corpus-graph","title":"Full Corpus Graph","text":"<p>The Full Corpus Graph brings your entire collection together in one interactive view. Click \"Generate Full Corpus Graph\" to render the complete network of interconnections across all papers.</p> <p>If the graph feels overwhelming, open the Advanced panel to filter which papers are included \u2014 then regenerate the graph to focus on what matters most. Like the ego graph, you can export this view as HTML for offline exploration.</p>"},{"location":"launch/","title":"How to Launch Text Lab","text":"<p>Text Lab runs as an interactive app on the University's High Performance Computing cluster (UBELIX) via the Open OnDemand portal.</p>"},{"location":"launch/#step-by-step-guide","title":"Step-by-Step Guide","text":"<ol> <li>Log in to the UBELIX Open OnDemand Portal.</li> <li>Navigate to Interactive Apps or Data Science Lab Services and select Text Lab.</li> <li>You will see a configuration form. Configure the resource requirements as follows:</li> </ol>"},{"location":"launch/#configuration-parameters","title":"Configuration Parameters","text":"Parameter Recommended Setting Description Account <code>gratis</code> Selects the type of account to launch Text Lab. SLURM Partition <code>gpu</code> Selects the partition with graphical processing units. QoS (Quality of Service) <code>job_gpu_preemptable</code> Use <code>job_gpu_preemptable</code> for quick tasks with a chance of being disconnected. Use <code>job_gpu</code> if you have a specific allocation. Job Time <code>1</code> to <code>4</code> hours Estimate how long you need the app. If the timer runs out, the session closes. GPU Type <code>rtx4090</code> The RTX4090 is powerful and sufficient for most Text Lab tasks (Transcription/OCR). Use A100/H100 only for very large LLM workloads. Certain LLMs will not run with RTX4090 Number of GPUs <code>1</code> One GPU is sufficient for standard usage. WCKey Optional Leave blank unless you have a specific project accounting key."},{"location":"launch/#advanced-mode","title":"Advanced Mode","text":"<p>Checking Advanced Mode allows you to specify a \"Reservation\" if you have code for for a workshop or course. Otherwise, leave this unchecked.</p>"},{"location":"launch/#starting-the-session","title":"Starting the Session","text":"<ol> <li>Click Launch.</li> <li>Wait for the job to start (the status will change from \"Queued\" to \"Running\").</li> <li>Click Connect to Text Lab to open the interface in your browser.</li> </ol>"},{"location":"launch/#more-info-on-the-configuration-parameters","title":"More info on the configuration parameters","text":"<p>Please check the UBELIX HPC documentation for more info on launching jobs: https://hpc-unibe-ch.github.io/</p>"},{"location":"ocr/","title":"Optical Character Recognition (OCR)","text":"<p>The OCR tool allows you to extract editable text from scanned PDF documents or images.</p>"},{"location":"ocr/#supported-input","title":"Supported Input","text":"<ul> <li>Files: PDF documents (<code>.pdf</code>).</li> <li>Note: If your PDF has multiple pages, the process may take several minutes per page depending on the density of the text.</li> </ul>"},{"location":"ocr/#choosing-an-engine","title":"Choosing an Engine","text":"<p>Text Lab provides three different AI engines for text extraction:</p> <ol> <li>EasyOCR (Default): Good for general purpose text and supports many languages.</li> <li>PaddleOCR: Often performs better on documents with complex layouts or tables.</li> <li>OlmOCR: A specialized pipeline for converting PDFs into clean Markdown.</li> </ol>"},{"location":"ocr/#how-to-use","title":"How to Use","text":"<ol> <li>Upload PDF: Select your file.</li> <li>Select Engine: Choose one of the engines listed above.</li> <li>Run OCR: Click the button to start processing.<ul> <li>Warning: Do not close the tab while the \"Running\" indicator is active.</li> </ul> </li> </ol>"},{"location":"ocr/#outputs","title":"Outputs","text":"<p>Once finished, you will see a side-by-side preview of the detected text boxes and the extracted content. You can download: * Extracted Text (.txt) * Structured Data (.jsonl): Useful for developers or data analysis. * Full Package (.zip): Includes text, JSON, and layout images.</p>"},{"location":"other_tools/","title":"Other Features","text":""},{"location":"other_tools/#ai-chat","title":"\ud83d\udcac AI Chat","text":"<p>Text Lab provides a secure Chat interface allowing you to interact with Large Language Models (LLMs) running locally on the University cluster. You can also upload documents with limted size and token number to summarize, translate and interact with.</p> <ul> <li>Privacy: Unlike public chatbots, your conversation history and prompts are not stored or used to train external models.</li> <li>Usage: Use this for summarizing sensitive text, brainstorming research ideas, or drafting emails.</li> </ul>"},{"location":"other_tools/#visualize-data","title":"\ud83d\udcca Visualize Data","text":"<p>This tool allows you to upload datasets (CSV/Excel) and use LLMs to generate Python code for visualization.</p> <ul> <li>Describe the plot you want to see (e.g., \"Show a bar chart of sales by region\").</li> <li>The system generates the code and renders the plot instantly.</li> </ul> <p>The visualisation is MCP system and has limited number of plots and options. The purpose of this feature to explore the data.</p>"},{"location":"transcription/","title":"Transcription Service","text":"<p>The Transcription tool uses WhisperX to convert spoken audio into written text with precise timestamps and speaker identification.</p>"},{"location":"transcription/#supported-formats","title":"Supported Formats","text":"<p>You can upload audio files in the following formats: * <code>.wav</code> * <code>.mp3</code> * <code>.flac</code> * <code>.m4a</code></p>"},{"location":"transcription/#how-to-use","title":"How to Use","text":"<ol> <li>Select Workflow: Choose \"Transcribe audio\" to process a new file.</li> <li>Upload File: Drag and drop your audio file or upload it.</li> <li>Language Selection: * The system will attempt to auto-detect the language.<ul> <li>Important: You must verify or manually select the correct language from the dropdown.</li> </ul> </li> </ol>"},{"location":"transcription/#swiss-german-support","title":"\ud83c\udde8\ud83c\udded Swiss German Support","text":"<p>Text Lab includes a specialized fine-tuned model for Swiss German.  * Select Swiss German from the language list. * This uses the <code>swhisper-large-1.1</code> model, which achieves a Word Error Rate (WER) of approximately 18, significantly outperforming standard models on Swiss German dialects. More info about the fine-tuned whisper will be published soon.</p>"},{"location":"transcription/#configuration-options","title":"Configuration Options","text":"<ul> <li>VAD (Voice Activity Detection)(Optional): * Check this to filter out silence before processing. <ul> <li>Max Pause: Determines how much silence is allowed between words before splitting a segment.</li> </ul> </li> <li>Speaker Diarization (Who is speaking?):<ul> <li>Min/Max Speakers (Optional): If you know how many people are in the recording, set these numbers to help the AI distinguish between voices (e.g., for an interview, set Min=2, Max=2). </li> </ul> </li> </ul>"},{"location":"transcription/#results-export","title":"Results &amp; Export","text":"<p>Once the transcription is complete, you can: * Preview: Listen to the audio with a synchronized interactive text player. * Edit View: Toggle between \"Segments\" (sentences) and \"Words\" view. * Download: * Text (.txt): Plain text transcript.     * CSV: Contains timestamps and speaker labels.     * ZIP: Download all formats and the processed WAV file in one package.</p>"}]}