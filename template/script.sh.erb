#!/usr/bin/env bash

set -euo pipefail

# Allow callers to override base directories via environment variables.
HOST_TEXT_LAB_DIR="${TEXT_LAB_DIR:-/storage/research/dsl_shared/solutions/ondemand/text_lab}"

CONT_TEXT_LAB_DIR="/text_lab"
CONT_OLMOCR_DIR="/olmocr"

TL_CONTAINER="$HOST_TEXT_LAB_DIR/container/text_lab.sif"
OCR_CONTAINER="$HOST_TEXT_LAB_DIR/container/olmocr.sif"

HOST_OLLAMA_DIR="../container/models/ollama"
CONT_OLLAMA_DIR="/opt/ollama"

export OCR_CONTAINER
export OLLAMA_MODELS="$CONT_OLLAMA_DIR/models"

# ---------------------------- Runtime parameters ------------------------------
# Which ports should each service listen on?
TEXT_LAB_PORT="${TEXT_LAB_PORT:-${SERVER_PORT:-8502}}"   # streamlit defaults to 8502 if not set
OLM_OCR_PORT="${OLMOCR_PORT:-8503}"

# Base URL path for reverseâ€‘proxy setups (JupyterHub, etc.). Leave empty for /
SERVER_BASEURLPATH="${SERVER_BASEURLPATH:-}"  # may already be exported by the hub

# --- Clean the Python environment ---
unset PYTHONPATH PYTHONHOME
export PYTHONNOUSERSITE=1

# Explicitly set HOME and USER for environment isolation
export HOME="$HOME"
export USER="$USER"

# Set the variable for whisper to use models cached from inside the container
export WHISPER_CACHE="/opt/whisper"

pushd "${PWD}"

echo "Running apptainer exec --nv '\$TL_CONTAINER' nvidia-smi"
apptainer exec --nv "$TL_CONTAINER" nvidia-smi

# Hard fail if the GPU is not visible inside the container
if $? != 0; then
  echo "FATAL: No GPU visible inside the container. Request a GPU and keep --nv."
  exit 1
fi

# If CUDA_VISIBLE_DEVICES is empty, unmask GPU 0 (or whatever your job grants)
if [ -z "${CUDA_VISIBLE_DEVICES:-}" ]; then
  export CUDA_VISIBLE_DEVICES=0
fi

apptainer exec \
  --nv \
  --bind "$HOST_TEXT_LAB_DIR:$CONT_TEXT_LAB_DIR" \
  --bind "$HOST_OLLAMA_DIR:$CONT_OLLAMA_DIR" \
  --env OLLAMA_MODELS="$CONT_OLLAMA_DIR/models" \
  --env OLLAMA_LLM_LIBRARY="cuda" \
  --env OLLAMA_FLASH_ATTENTION="true" \
  "$TL_CONTAINER" \
  /usr/bin/python3 -m streamlit run "$CONT_TEXT_LAB_DIR/src/Home.py" \
    --server.address 0.0.0.0 \
    --server.port "$TEXT_LAB_PORT" \
    --server.baseUrlPath "$SERVER_BASEURLPATH" \
    --server.headless true \
    --server.maxUploadSize 500 \
    --browser.serverAddress ondemand.hpc.unibe.ch \
    --browser.gatherUsageStats false \
    --logger.level debug

popd
